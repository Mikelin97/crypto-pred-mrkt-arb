
services:
  kafka:
    image: apache/kafka-native:4.1.1
    container_name: kafka
    healthcheck:
      test: ["CMD-SHELL", "bash -c '</dev/tcp/127.0.0.1/9092'"]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 60s
    environment:
      - KAFKA_NODE_ID=1
      - KAFKA_CLUSTER_ID=MkU3OEVBNTcwNTJENDM2Qk
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092,EXTERNAL://0.0.0.0:19092,CONTROLLER://0.0.0.0:9093
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://localhost:19092
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
      - KAFKA_NUM_PARTITIONS=3
    ports:
      # Internal listener stays 9092 (for containers); external listener exposed on 19092 for host clients.
      - "19092:19092"
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - default
      - data_pipeline

  kafka_bridge:
    build:
      context: ..
      dockerfile: transform_layer/Dockerfile
    container_name: transform_kafka_bridge
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - SERVICE=kafka_bridge
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      # Point at Redis in the inflow network
      - REDIS_URL=redis://redis:6379/0
      - REDIS_CHANNEL_PATTERNS=markets.crypto:*
      - KAFKA_RAW_TOPIC=market.raw
      - KAFKA_PERSIST_TOPIC=market.persisted
      # Optional: uncomment to backfill from Postgres
      # - POSTGRES_DSN=postgresql://postgres:postgres@persistence_postgres:5432/postgres
      # - PERSISTENCE_QUERY=SELECT * FROM kafka_events ORDER BY ingested_at DESC LIMIT 1000
    networks:
      - default
      - inflow_gateway
      - data_pipeline

  transform_writer:
    build:
      context: ..
      dockerfile: transform_layer/Dockerfile
    container_name: transform_writer
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - SERVICE=transform_writer
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_RAW_TOPIC=market.raw
      - KAFKA_PERSIST_TOPIC=market.persisted
      - KAFKA_CONSUMER_GROUP=transform-writer
      - POSTGRES_DSN=postgresql://postgres:postgres@persistence_postgres:5432/postgres
      - ORDER_BOOK_UPDATES_TABLE=order_book_updates
      - ORDER_BOOK_SNAPSHOTS_TABLE=order_book_snapshots
      - BATCH_SIZE=500
      - BATCH_INTERVAL_SECONDS=1.0
    networks:
      - default
      - data_pipeline

  debezium:
    image: debezium/connect:2.7.3.Final
    container_name: transform_debezium
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - BOOTSTRAP_SERVERS=kafka:9092
      - GROUP_ID=debezium-connect
      - CONFIG_STORAGE_TOPIC=debezium_connect_configs
      - OFFSET_STORAGE_TOPIC=debezium_connect_offsets
      - STATUS_STORAGE_TOPIC=debezium_connect_status
      - CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1
      - CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1
      - CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1
      - KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter
      - VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter
      - KEY_CONVERTER_SCHEMAS_ENABLE=false
      - VALUE_CONVERTER_SCHEMAS_ENABLE=false
      - REST_ADVERTISED_HOST_NAME=debezium
    ports:
      - "18083:8083"
    networks:
      - default
      - data_pipeline

  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: transform_clickhouse
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - CLICKHOUSE_DB=analytics
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
      - CLICKHOUSE_PASSWORD=clickhouse
      - CLICKHOUSE_LISTEN_HOST=0.0.0.0
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./template.sql:/docker-entrypoint-initdb.d/01_template.sql:ro
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    networks:
      - default
      - data_pipeline

volumes:
  kafka_data:
  clickhouse_data:

networks:
  default:
    driver: bridge
  inflow_gateway:
    external: true
  data_pipeline:
    external: true
